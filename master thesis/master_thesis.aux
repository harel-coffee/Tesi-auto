\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand \oddpage@label [2]{}
\citation{*}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{9}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{fong}
\citation{healthcare}
\citation{real_time_image_saliency}
\citation{lime}
\citation{ilsvrc}
\citation{survey}
\citation{global1,global2,global3}
\citation{huysmans}
\citation{inspection1,inspection2}
\citation{transparent1,transparent2,transparent3}
\citation{survey}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Related work}{13}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapt:related-work}{{2}{13}{Related work}{chapter.2}{}}
\citation{show-and-tell}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Image Captioning}{14}{section.2.1}}
\citation{show_attend_and_tell}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Example of generation of a caption. White areas in the images visualize the attention for each of the corresponding words of the generated caption\footnotemark .\relax }}{15}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:show-attend}{{2.1}{15}{Example of generation of a caption. White areas in the images visualize the attention for each of the corresponding words of the generated caption\protect \footnotemark .\relax }{figure.caption.4}{}}
\citation{neural-attention}
\citation{fong}
\citation{fong}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Explanation via Saliency Masks}{16}{section.2.2}}
\citation{fong}
\citation{real_time_image_saliency}
\citation{obj-detectors}
\newlabel{subfig:grad-cam-orig}{{2.2a}{17}{Original image\relax }{figure.caption.5}{}}
\newlabel{sub@subfig:grad-cam-orig}{{a}{17}{Original image\relax }{figure.caption.5}{}}
\newlabel{subfig:grad-cam-mask}{{2.2b}{17}{Class Activation Mapping\relax }{figure.caption.5}{}}
\newlabel{sub@subfig:grad-cam-mask}{{b}{17}{Class Activation Mapping\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Grad-CAM: the image on the left is the original one, while the one on the right defines the Class Activation Mapping for the label \textit  {boxer}\footnotemark .\relax }}{17}{figure.caption.5}}
\newlabel{fig:grad-cam}{{2.2}{17}{Grad-CAM: the image on the left is the original one, while the one on the right defines the Class Activation Mapping for the label \textit {boxer}\protect \footnotemark .\relax }{figure.caption.5}{}}
\newlabel{eqn:saliency-metric}{{2.3}{17}{Explanation via Saliency Masks}{equation.2.2.3}{}}
\citation{zhou,gradcam}
\citation{interpretable-convnets}
\citation{interpretable-convnets}
\citation{interpretable-convnets}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Alternative image data representations}{18}{section.2.3}}
\citation{bag-of-pixels}
\citation{bag-of-keypoints,yang-visual-words,yang2-visual-words,old-visual-words,visual-word-reconstruction}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Comparison of the features of a traditional CNN and an interpretable CNN. Filters of the first one identify different patterns at the same time (e.g. ear and legs of a kitten), while interpretable filters only highlight a single part which, in this case, is the kitten's face (image taken from \cite  {interpretable-convnets}).\relax }}{19}{figure.caption.6}}
\newlabel{fig:interpretable-convnets}{{2.3}{19}{Comparison of the features of a traditional CNN and an interpretable CNN. Filters of the first one identify different patterns at the same time (e.g. ear and legs of a kitten), while interpretable filters only highlight a single part which, in this case, is the kitten's face (image taken from \cite {interpretable-convnets}).\relax }{figure.caption.6}{}}
\citation{sift}
\citation{visual-bag-of-words}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Example showing the visual bag-of-words generation process. From each image, we extract a set of features and use them to build the visual vocabulary (shown in the X-axis of the histograms)\footnotemark .\relax }}{20}{figure.caption.7}}
\newlabel{fig:visual-bag}{{2.4}{20}{Example showing the visual bag-of-words generation process. From each image, we extract a set of features and use them to build the visual vocabulary (shown in the X-axis of the histograms)\protect \footnotemark .\relax }{figure.caption.7}{}}
\citation{visual-bag-of-words}
\citation{show-and-tell,show_attend_and_tell}
\citation{gradcam,neural-attention,zhou}
\citation{gradcam,neural-attention,zhou}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Comparison with the state of the art}{21}{section.2.4}}
\citation{fong}
\citation{bag-of-keypoints,yang-visual-words,yang2-visual-words,old-visual-words,visual-word-reconstruction,bag-of-pixels,visual-bag-of-words}
\citation{lime}
\citation{lime}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Background: LIME}{23}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapt:background}{{3}{23}{Background: LIME}{chapter.3}{}}
\newlabel{fig:decision_bound}{{3.1}{24}{}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Explaining the predictions}{24}{section.3.1}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}The need for interpretability and fidelity}{25}{section.3.2}}
\newlabel{eqn:bestmodel}{{3.1}{25}{The need for interpretability and fidelity}{equation.3.2.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Generation of the neighborhood}{26}{section.3.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The neighborhood generation process adopted by LIME. \textit  {\csqQQ {34}red fox\csqQQ {34}} is the prediction we want to explain. The first row of the matrix (highlighted in blue) is the IDR of the original image, and the remaining ones represent images in the neighborhood.\relax }}{27}{figure.caption.9}}
\newlabel{fig:neighborhood_generation}{{3.2}{27}{The neighborhood generation process adopted by LIME. \textit {"red fox"} is the prediction we want to explain. The first row of the matrix (highlighted in blue) is the IDR of the original image, and the remaining ones represent images in the neighborhood.\relax }{figure.caption.9}{}}
\citation{quickshift}
\citation{meanshift}
\citation{healthcare}
\newlabel{subfig:insight_orig}{{3.3a}{29}{Original image.\relax }{figure.caption.10}{}}
\newlabel{sub@subfig:insight_orig}{{a}{29}{Original image.\relax }{figure.caption.10}{}}
\newlabel{subfig:insight_exp}{{3.3b}{29}{Explanation for \emph {candle}.\relax }{figure.caption.10}{}}
\newlabel{sub@subfig:insight_exp}{{b}{29}{Explanation for \emph {candle}.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Example of explanation of a wrong prediction: the original image was meant to represent a \emph  {hotdog} (image on the \textbf  {left}), while the predicted label is \emph  {candle} (image on the \textbf  {right}).\relax }}{29}{figure.caption.10}}
\newlabel{fig:insight}{{3.3}{29}{Example of explanation of a wrong prediction: the original image was meant to represent a \emph {hotdog} (image on the \textbf {left}), while the predicted label is \emph {candle} (image on the \textbf {right}).\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}Gaining insights about wrong predictions}{29}{section.3.4}}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Proposed approach}{31}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapt:approach}{{4}{31}{Proposed approach}{chapter.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Sample image to be explained by all the versions of LIME. The correct prediction for it is \emph  {tricycle}.\relax }}{32}{figure.caption.11}}
\newlabel{fig:tricycle}{{4.1}{32}{Sample image to be explained by all the versions of LIME. The correct prediction for it is \emph {tricycle}.\relax }{figure.caption.11}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}LIME}{32}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Neighborhood images generated by LIME gray (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{33}{figure.caption.12}}
\newlabel{fig:lime_neigh}{{4.2}{33}{Neighborhood images generated by LIME gray (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Neighborhood images generated by LIME color (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{34}{figure.caption.13}}
\newlabel{fig:limecolor_neigh}{{4.3}{34}{Neighborhood images generated by LIME color (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}LIME$\#$}{34}{section.4.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Neighborhood images generated by LIME\# gray (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{35}{figure.caption.14}}
\newlabel{fig:limesharp_neigh}{{4.4}{35}{Neighborhood images generated by LIME\# gray (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Image-based neighborhood approaches}{35}{section.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Neighborhood images generated by LIME\# color (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{36}{figure.caption.15}}
\newlabel{fig:limesharpcolor_neigh}{{4.5}{36}{Neighborhood images generated by LIME\# color (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}LIME$\#$R}{36}{subsection.4.3.1}}
\newlabel{eqn:image_pool}{{4.1}{36}{LIME$\#$R}{equation.4.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces The neighborhood generation process adopted by image-based neighborhood approaches (LIME\#R and LIME\#C). \textit  {\csqQQ {34}red fox\csqQQ {34}} is the prediction we want to explain.\relax }}{37}{figure.caption.16}}
\newlabel{fig:img-based_neigh}{{4.6}{37}{The neighborhood generation process adopted by image-based neighborhood approaches (LIME\#R and LIME\#C). \textit {"red fox"} is the prediction we want to explain.\relax }{figure.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Neighborhood images generated by LIME\#R (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{38}{figure.caption.17}}
\newlabel{fig:limesharpR_neigh}{{4.7}{38}{Neighborhood images generated by LIME\#R (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}LIME$\#$C}{38}{subsection.4.3.2}}
\newlabel{eqn:limesharpC_pool}{{4.2}{38}{LIME$\#$C}{equation.4.3.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Neighborhood images generated by LIME\#C (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit  {tricycle} (\textbf  {bottom-right}).\relax }}{39}{figure.caption.18}}
\newlabel{fig:limesharpC_neigh}{{4.8}{39}{Neighborhood images generated by LIME\#C (images from 1 to 5, counting from left to right and from top to bottom) and explanation for the label \textit {tricycle} (\textbf {bottom-right}).\relax }{figure.caption.18}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces A small sample of the images belonging to the same cluster as the image in Figure \ref  {fig:tricycle}.\relax }}{40}{figure.caption.19}}
\newlabel{fig:limesharpC_same_clus}{{4.9}{40}{A small sample of the images belonging to the same cluster as the image in Figure \ref {fig:tricycle}.\relax }{figure.caption.19}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Toy example that shows how to proceed in the computation of the \textit  {Clustering Purity}.\relax }}{40}{table.caption.21}}
\newlabel{tab:cluster_purity_example}{{4.1}{40}{Toy example that shows how to proceed in the computation of the \textit {Clustering Purity}.\relax }{table.caption.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{Definition of \textit  {Clustering Purity}}{40}{section*.20}}
\newlabel{subfig:undersamp-orig}{{4.10a}{41}{Original image, before the undersampling process.\relax }{figure.caption.23}{}}
\newlabel{sub@subfig:undersamp-orig}{{a}{41}{Original image, before the undersampling process.\relax }{figure.caption.23}{}}
\newlabel{subfig:undersamp-und}{{4.10b}{41}{Undersampled image. New size is 8x8 pixels.\relax }{figure.caption.23}{}}
\newlabel{sub@subfig:undersamp-und}{{b}{41}{Undersampled image. New size is 8x8 pixels.\relax }{figure.caption.23}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Representation of the effect of the undersampling process. The image on the left (Figure \ref  {subfig:undersamp-orig}) is the original image, and the one on the right (Figure \ref  {subfig:undersamp-und}) is the result of the application of an undersampling process with $grid\_size = 8$.\relax }}{41}{figure.caption.23}}
\newlabel{fig:undersamp-example}{{4.10}{41}{Representation of the effect of the undersampling process. The image on the left (Figure \ref {subfig:undersamp-orig}) is the original image, and the one on the right (Figure \ref {subfig:undersamp-und}) is the result of the application of an undersampling process with $grid\_size = 8$.\relax }{figure.caption.23}{}}
\@writefile{toc}{\contentsline {subsubsection}{Clustering algorithm}{41}{section*.22}}
\citation{k-means}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces K-means clustering algorithm.\relax }}{42}{algocf.1}}
\newlabel{alg:kmeans}{{1}{42}{Clustering algorithm}{algocf.1}{}}
\citation{on-spectral-clus,spectral_clustering,spectral-tutorial}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Summary of the different versions of LIME.\relax }}{44}{table.caption.25}}
\newlabel{tab:lime_versions}{{4.2}{44}{Summary of the different versions of LIME.\relax }{table.caption.25}{}}
\citation{inception-v3}
\citation{inception-v1}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Experiments}{45}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapt:experiments}{{5}{45}{Experiments}{chapter.5}{}}
\citation{inception-v1}
\citation{inception-v1}
\citation{inception-v3}
\citation{inception-v3}
\citation{inception-v3}
\citation{inception-v3}
\citation{inception-v3}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Black box model}{46}{section.5.1}}
\citation{ilsvrc}
\newlabel{subfig:inception-v1}{{5.1a}{47}{Original Inception v1 module, containing expensive 5x5 convolutions (described in \cite {inception-v1}).\relax }{figure.caption.26}{}}
\newlabel{sub@subfig:inception-v1}{{a}{47}{Original Inception v1 module, containing expensive 5x5 convolutions (described in \cite {inception-v1}).\relax }{figure.caption.26}{}}
\newlabel{subfig:inception-v3}{{5.1b}{47}{Inception v3 module: 5x5 convolutions are replaced by two 3x3 convolutions (described in \cite {inception-v3}).\relax }{figure.caption.26}{}}
\newlabel{sub@subfig:inception-v3}{{b}{47}{Inception v3 module: 5x5 convolutions are replaced by two 3x3 convolutions (described in \cite {inception-v3}).\relax }{figure.caption.26}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Comparison between Inception v1 and Inception v3 modules. Both images were taken from \cite  {inception-v3}.\relax }}{47}{figure.caption.26}}
\newlabel{fig:inception-versions}{{5.1}{47}{Comparison between Inception v1 and Inception v3 modules. Both images were taken from \cite {inception-v3}.\relax }{figure.caption.26}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Dataset}{47}{section.5.2}}
\newlabel{sect:dataset_used}{{5.2}{47}{Dataset}{section.5.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Chosen classes (from ILSVRC2012 data set) for the construction of the data set used in the experiments. For each of the 20 classes, we picked all the 50 corresponding images (1000 in total).\relax }}{48}{table.caption.27}}
\newlabel{tab:chosen_classes}{{5.1}{48}{Chosen classes (from ILSVRC2012 data set) for the construction of the data set used in the experiments. For each of the 20 classes, we picked all the 50 corresponding images (1000 in total).\relax }{table.caption.27}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}Definition of \textit  {reference area}}{48}{subsection.5.2.1}}
\newlabel{subfig:gt_orig}{{5.2a}{49}{Original image. The label to be explained is \textit {bicycle-built-for-two}.\relax }{figure.caption.28}{}}
\newlabel{sub@subfig:gt_orig}{{a}{49}{Original image. The label to be explained is \textit {bicycle-built-for-two}.\relax }{figure.caption.28}{}}
\newlabel{subfig:gt_groundtruth}{{5.2b}{49}{Image defining the reference area for \textit {bicycle-built-for-two}.\relax }{figure.caption.28}{}}
\newlabel{sub@subfig:gt_groundtruth}{{b}{49}{Image defining the reference area for \textit {bicycle-built-for-two}.\relax }{figure.caption.28}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Example of cropped image that defines the reference area for \textit  {bicycle-built-for-two}: the more an explanation covers it, the better. The image on the left (Figure \ref  {subfig:gt_orig}) is the original one, while the one on the right (Figure \ref  {subfig:gt_groundtruth}) highlights the silhouette of the bicycle.\relax }}{49}{figure.caption.28}}
\newlabel{fig:ground_truth}{{5.2}{49}{Example of cropped image that defines the reference area for \textit {bicycle-built-for-two}: the more an explanation covers it, the better. The image on the left (Figure \ref {subfig:gt_orig}) is the original one, while the one on the right (Figure \ref {subfig:gt_groundtruth}) highlights the silhouette of the bicycle.\relax }{figure.caption.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Evaluation}{49}{section.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Toy example that explains the computation of the precision, recall and F-measure measures. For simplicity, we suppose each square is a pixel and each green area is a feature. The T-shaped blue part is the reference area, while the green areas are the highlighted features of the explanation.\relax }}{50}{figure.caption.29}}
\newlabel{fig:measures}{{5.3}{50}{Toy example that explains the computation of the precision, recall and F-measure measures. For simplicity, we suppose each square is a pixel and each green area is a feature. The T-shaped blue part is the reference area, while the green areas are the highlighted features of the explanation.\relax }{figure.caption.29}{}}
\newlabel{eqn:precision}{{5.1}{50}{Evaluation}{equation.5.3.1}{}}
\newlabel{eqn:recall}{{5.2}{50}{Evaluation}{equation.5.3.2}{}}
\newlabel{eqn:fmeasure}{{5.3}{50}{Evaluation}{equation.5.3.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Results}{51}{section.5.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}LIME\# gray}{51}{subsection.5.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces LIME\# gray: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }}{52}{figure.caption.30}}
\newlabel{subfig:limesharp_gray_vs_sf}{{5.4}{52}{LIME\# gray: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }{figure.caption.30}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces LIME\# color: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }}{53}{figure.caption.31}}
\newlabel{subfig:limesharp_color_vs_sf}{{5.5}{53}{LIME\# color: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }{figure.caption.31}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}LIME\# color}{53}{subsection.5.4.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}LIME\#R}{53}{subsection.5.4.3}}
\newlabel{sect:limesharpR_expe}{{5.4.3}{53}{LIME\#R}{subsection.5.4.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces LIME\#R: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }}{54}{figure.caption.32}}
\newlabel{subfig:limesharp_R_vs_sf}{{5.6}{54}{LIME\#R: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }{figure.caption.32}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.4}LIME\#C}{54}{subsection.5.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Values of the silhouette coefficient for different number of clusters. Clustering has been computed on images of size 8x8 pixels.\relax }}{55}{figure.caption.34}}
\newlabel{fig:spectral-silhouette}{{5.7}{55}{Values of the silhouette coefficient for different number of clusters. Clustering has been computed on images of size 8x8 pixels.\relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {subsubsection}{Choice of the clustering algorithm}{55}{section*.33}}
\@writefile{toc}{\contentsline {subsubsection}{Explanation performances}{56}{section*.35}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces LIME\#C: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }}{57}{figure.caption.36}}
\newlabel{subfig:limesharp_C_vs_sf}{{5.8}{57}{LIME\#C: Precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }{figure.caption.36}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Comparison between LIME\#R and LIME\#C of precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }}{58}{figure.caption.37}}
\newlabel{subfig:R-C-comparison}{{5.9}{58}{Comparison between LIME\#R and LIME\#C of precision, recall and F-measure for increasing values of the parameter $shown\_features$.\relax }{figure.caption.37}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Trend of precision for increasing values of $shown\_features$. Fixing the value of $grid\_size$ to 8, we make a comparison between the newly proposed approaches (all the \csqQQ {34}\#\csqQQ {34} variants of LIME).\relax }}{59}{figure.caption.38}}
\newlabel{fig:overall-prec}{{5.10}{59}{Trend of precision for increasing values of $shown\_features$. Fixing the value of $grid\_size$ to 8, we make a comparison between the newly proposed approaches (all the "\#" variants of LIME).\relax }{figure.caption.38}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Overall comparison}{59}{section.5.5}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Precision (mean $\pm $ standard dev.) for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{60}{table.caption.39}}
\newlabel{tab:overall-precision-avg}{{5.2}{60}{Precision (mean $\pm $ standard dev.) for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.39}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Median of the precision for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{60}{table.caption.40}}
\newlabel{tab:overall-precision-median}{{5.3}{60}{Median of the precision for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.40}{}}
\citation{lime}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{61}{chapter.6}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{chapt:conclusions}{{6}{61}{Conclusion}{chapter.6}{}}
\bibstyle{ieeetr}
\bibdata{biblio}
\bibcite{ilsvrc}{1}
\bibcite{inception-v1}{2}
\bibcite{inception-v3}{3}
\bibcite{healthcare}{4}
\bibcite{quickshift}{5}
\bibcite{meanshift}{6}
\bibcite{lore}{7}
\bibcite{lime}{8}
\bibcite{gradcam}{9}
\bibcite{interpretable-convnets}{10}
\bibcite{neural-attention}{11}
\bibcite{fong}{12}
\bibcite{survey}{13}
\bibcite{obj-detectors}{14}
\bibcite{a-model-explanation}{15}
\bibcite{nothing-else-matters}{16}
\bibcite{zhou}{17}
\bibcite{global1}{18}
\bibcite{global2}{19}
\bibcite{global3}{20}
\bibcite{transparent1}{21}
\bibcite{transparent2}{22}
\bibcite{transparent3}{23}
\bibcite{neural_pred}{24}
\bibcite{bag-of-pixels}{25}
\bibcite{bag-of-keypoints}{26}
\bibcite{yang-visual-words}{27}
\bibcite{yang2-visual-words}{28}
\bibcite{visual-word-reconstruction}{29}
\bibcite{old-visual-words}{30}
\bibcite{visual-bag-of-words}{31}
\bibcite{sift}{32}
\bibcite{show-and-tell}{33}
\bibcite{show_attend_and_tell}{34}
\bibcite{inspection1}{35}
\bibcite{inspection2}{36}
\bibcite{huysmans}{37}
\bibcite{real_time_image_saliency}{38}
\bibcite{k-means}{39}
\bibcite{on-spectral-clus}{40}
\bibcite{spectral-tutorial}{41}
\bibcite{spectral_clustering}{42}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Experiments results}{69}{appendix.A}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {A.1}{\ignorespaces Trends of recall and F-measure for increasing values of $shown\_features$. Fixing the value of $grid\_size$ to 8, we make a comparison between the newly proposed approaches (all the \csqQQ {34}\#\csqQQ {34} variants of LIME).\relax }}{69}{figure.caption.42}}
\newlabel{fig:overall-rec-fmea}{{A.1}{69}{Trends of recall and F-measure for increasing values of $shown\_features$. Fixing the value of $grid\_size$ to 8, we make a comparison between the newly proposed approaches (all the "\#" variants of LIME).\relax }{figure.caption.42}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Recall (mean $\pm $ standard dev.) for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{70}{table.caption.49}}
\newlabel{tab:overall-recall-avg}{{A.1}{70}{Recall (mean $\pm $ standard dev.) for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.49}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Median of the recall for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{70}{table.caption.50}}
\newlabel{tab:overall-recall-median}{{A.2}{70}{Median of the recall for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.50}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces F-measure (mean $\pm $ standard dev.) for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{71}{table.caption.51}}
\newlabel{tab:overall-fmeasure-avg}{{A.3}{71}{F-measure (mean $\pm $ standard dev.) for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.51}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Median of the F-measure for all the versions of LIME (for all the \csqQQ {34}\#\csqQQ {34} variants, we have set $grid\_size = 8$).\relax }}{71}{table.caption.52}}
\newlabel{tab:overall-fmeasure-median}{{A.4}{71}{Median of the F-measure for all the versions of LIME (for all the "\#" variants, we have set $grid\_size = 8$).\relax }{table.caption.52}{}}
\newlabel{subfig:limesharp_gray_prec_vs_gs}{{A.2a}{72}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\newlabel{sub@subfig:limesharp_gray_prec_vs_gs}{{a}{72}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\newlabel{subfig:limesharp_gray_rec_vs_gs}{{A.2b}{72}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\newlabel{sub@subfig:limesharp_gray_rec_vs_gs}{{b}{72}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\newlabel{subfig:limesharp_gray_fmea_vs_gs}{{A.2c}{72}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\newlabel{sub@subfig:limesharp_gray_fmea_vs_gs}{{c}{72}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.43}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.2}{\ignorespaces LIME\# gray: evaluating explanations as the grid size (in the X-axis) increases.\relax }}{72}{figure.caption.43}}
\newlabel{fig:limesharp_gray_vs_gs}{{A.2}{72}{LIME\# gray: evaluating explanations as the grid size (in the X-axis) increases.\relax }{figure.caption.43}{}}
\newlabel{subfig:limesharp_color_prec_vs_gs}{{A.3a}{73}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\newlabel{sub@subfig:limesharp_color_prec_vs_gs}{{a}{73}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\newlabel{subfig:limesharp_color_rec_vs_gs}{{A.3b}{73}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\newlabel{sub@subfig:limesharp_color_rec_vs_gs}{{b}{73}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\newlabel{subfig:limesharp_color_fmea_vs_gs}{{A.3c}{73}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\newlabel{sub@subfig:limesharp_color_fmea_vs_gs}{{c}{73}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.44}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.3}{\ignorespaces LIME\# color: evaluating explanations as the grid size (in the X-axis) increases.\relax }}{73}{figure.caption.44}}
\newlabel{fig:limesharp_color_vs_gs}{{A.3}{73}{LIME\# color: evaluating explanations as the grid size (in the X-axis) increases.\relax }{figure.caption.44}{}}
\newlabel{subfig:limesharp_R_prec_vs_gs}{{A.4a}{74}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\newlabel{sub@subfig:limesharp_R_prec_vs_gs}{{a}{74}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\newlabel{subfig:limesharp_R_rec_vs_gs}{{A.4b}{74}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\newlabel{sub@subfig:limesharp_R_rec_vs_gs}{{b}{74}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\newlabel{subfig:limesharp_R_fmea_vs_gs}{{A.4c}{74}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\newlabel{sub@subfig:limesharp_R_fmea_vs_gs}{{c}{74}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.45}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.4}{\ignorespaces LIME\#R: evaluating explanations as the grid size (in the X-axis) increases.\relax }}{74}{figure.caption.45}}
\newlabel{fig:limesharp_R_vs_gs}{{A.4}{74}{LIME\#R: evaluating explanations as the grid size (in the X-axis) increases.\relax }{figure.caption.45}{}}
\newlabel{subfig:purity-4}{{A.5a}{75}{Clustering purity and SSE curve for $grid\_size = 4$.\relax }{figure.caption.46}{}}
\newlabel{sub@subfig:purity-4}{{a}{75}{Clustering purity and SSE curve for $grid\_size = 4$.\relax }{figure.caption.46}{}}
\newlabel{subfig:purity-8}{{A.5b}{75}{Clustering purity and SSE curve for $grid\_size = 8$.\relax }{figure.caption.46}{}}
\newlabel{sub@subfig:purity-8}{{b}{75}{Clustering purity and SSE curve for $grid\_size = 8$.\relax }{figure.caption.46}{}}
\newlabel{subfig:purity-16}{{A.5c}{75}{Clustering purity and SSE curve for $grid\_size = 16$.\relax }{figure.caption.46}{}}
\newlabel{sub@subfig:purity-16}{{c}{75}{Clustering purity and SSE curve for $grid\_size = 16$.\relax }{figure.caption.46}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Clustering Purity and SSE curve for different values of $grid\_size$. The latter is used to find the best value of the parameter K, while the former is just a post-evaluation measure.\relax }}{75}{figure.caption.46}}
\newlabel{subfig:purity-32}{{A.5d}{76}{Clustering purity and SSE curve for $grid\_size = 32$.\relax }{figure.caption.47}{}}
\newlabel{sub@subfig:purity-32}{{d}{76}{Clustering purity and SSE curve for $grid\_size = 32$.\relax }{figure.caption.47}{}}
\newlabel{subfig:purity-64}{{A.5e}{76}{Clustering purity and SSE curve for $grid\_size = 64$.\relax }{figure.caption.47}{}}
\newlabel{sub@subfig:purity-64}{{e}{76}{Clustering purity and SSE curve for $grid\_size = 64$.\relax }{figure.caption.47}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.5}{\ignorespaces Clustering Purity and SSE curve for different values of $grid\_size$. The latter is used to find the best value of the parameter K, while the former is just a post-evaluation measure.\relax }}{76}{figure.caption.47}}
\newlabel{fig:purity}{{A.5}{76}{Clustering Purity and SSE curve for different values of $grid\_size$. The latter is used to find the best value of the parameter K, while the former is just a post-evaluation measure.\relax }{figure.caption.47}{}}
\newlabel{subfig:limesharp_C_prec_vs_gs}{{A.6a}{77}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\newlabel{sub@subfig:limesharp_C_prec_vs_gs}{{a}{77}{Precision for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\newlabel{subfig:limesharp_C_rec_vs_gs}{{A.6b}{77}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\newlabel{sub@subfig:limesharp_C_rec_vs_gs}{{b}{77}{Recall for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\newlabel{subfig:limesharp_C_fmea_vs_gs}{{A.6c}{77}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\newlabel{sub@subfig:limesharp_C_fmea_vs_gs}{{c}{77}{F-measure for increasing values of $grid\_size$.\relax }{figure.caption.48}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {A.6}{\ignorespaces LIME\#C: evaluating explanations as the grid size (in the X-axis) increases.\relax }}{77}{figure.caption.48}}
\newlabel{fig:limesharp_C_vs_gs}{{A.6}{77}{LIME\#C: evaluating explanations as the grid size (in the X-axis) increases.\relax }{figure.caption.48}{}}
